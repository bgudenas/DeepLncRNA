---
title: "cell_DTE"
author: "Brian Gudenas"
date: "December 21, 2017"
output: word_document
---

#1. Differential Transcript Expression 
Here we identify transcripts differentially localized in the cytosolic versus nuclear subcellular fractions from fractionated immortalized cell line RNA-seq data from ENCODE.

```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
opts_knit$set(root.dir = "..")
```

```{r Libraries, message = FALSE, warning = FALSE}
library(readr)
library(stringr)
library(sleuth)
library(dplyr)
library(RUVSeq)
library(RColorBrewer)
library(pheatmap)
```


```{r metadata, message = FALSE, warning = FALSE}
## load Sample Metadata 
samples = read_tsv("./Data/Meta/metadata.tsv")
colnames(samples) = make.names(colnames(samples))
Pair = read.table("./Data/Meta/Pair_map.txt", sep="\t", header = TRUE)

samples = samples[!is.na(match(samples$File.accession, Pair$Pair1)), ]

samples = samples[samples$Biosample.subcellular.fraction.term.name == "nucleus" | samples$Biosample.subcellular.fraction.term.name == "cytosol", ]

samples$Library.depleted.in[is.na(samples$Library.depleted.in)] = "rRNA"
samples$Lib_method = paste0(samples$Library.made.from,"_", samples$Library.depleted.in)

# ## Remove any samples with missing ERCC spikeins
# samples = samples[!grepl("spikeins", samples$Audit.WARNING), ]

s2c = dplyr::select(samples, sample = File.accession, condition = Biosample.subcellular.fraction.term.name, cell = Biosample.term.name, platform = Platform, Lib = Lib_method, reads = Read.length, warning = Audit.WARNING)

## Remove any cell types with less than 4 total samples
s2c = s2c[is.na(match(s2c$cell, names(table(s2c$cell))[table(s2c$cell) < 4] ) ),   ]

filespath = file.path(getwd(), "/Data/Kallisto/Quant", s2c$sample)
s2c = dplyr::mutate(s2c, path = filespath)

## Total samples
nrow(s2c)
## Samples per fraction
table(s2c$condition)
## Samples per Library type
table(s2c$Lib)
## Cell types
table(s2c$cell)

## Kallisto.o* is the standard output from the kallisto quant call for all samples
output = read.delim(file = "./Data/Kallisto/Kallisto.o2139569", sep = "\n")
pairmap = read.delim(file ="./Data/Meta/Pair_map.txt")

alignments = output[grepl("processed", output[,1]), ]


pairmap$total_reads = as.numeric(str_trim(str_replace_all(unlist(lapply(str_split(unlist(lapply(str_split(unlist(lapply(str_split(alignments, ", "), "[[", 1)), " reads"), "[[", 1)), "processed"),"[[",2)),",","")))
pairmap$reads_aligned = as.numeric(str_replace_all(unlist(lapply(str_split(unlist(lapply(str_split(alignments, ", "), "[[", 2)), " reads"), "[[", 1)), ",",""))

pairmap$percent_aligned = pairmap$reads_aligned/pairmap$total_reads*100
s2c$total_reads = pairmap$total_reads[match(s2c$sample, pairmap$Pair1)]
s2c$reads_aligned = pairmap$reads_aligned[match(s2c$sample, pairmap$Pair1)]

## total aligned reads
sum(s2c$reads_aligned)

#rm(alignments, samples, pairmap, Pair, output)
write.csv(s2c, "./Data/Meta/Sample_Meta.csv")
```

## DTE by cell type
Perform differential transcript expression analysis for each cell type. If a cell type contains more than a single RNA library construction protocol then we normalize these samples based on ERCC control spike ins,
otherwise we do the standard DE test. For each cell type we plot the PCA of the sleuth normalized counts and if available, the RUVg spike in normalized counts. Lastly, we use the bonferroni correction to adjust the alpha level for the number of cell types tested, resulting in a q-value threshold  of `r 0.05/length(unique(s2c$cell))`


```{r DTE_loop, cache = TRUE, warning = FALSE, message= FALSE}

master =c()
for ( i in unique(s2c$cell)){
  s2c_tmp = dplyr::filter(s2c, cell == i) %>% arrange(sample)
  
  so = sleuth_prep(s2c_tmp, transformation_function = function(x) log2(x+0.5) )
  lds = plot_pc_variance(so)

plot_pca(so, color_by = "condition",  text_labels = TRUE) + xlab(paste("PC1","%Var =", round(lds$data[1,2],2))) + ylab(paste("PC2","Var =", round(lds$data[2,2],2)))
  
  ## if more than 1  RNA-seq library protocols were used
  ## we normalize these cases by ERCC spikeins
if (length(unique(s2c_tmp$Lib))  > 1 ) {
    
    so <- sleuth_fit(so, ~ Lib + condition, 'full')
    so <- sleuth_fit(so, ~ Lib, 'reduced')
    #so <- sleuth_lrt(so, 'reduced', 'full')
    so = sleuth_wt(so, "conditionnucleus")
    wt_results = sleuth_results(so, 'conditionnucleus')
    res =wt_results[!is.na(wt_results$pval), ]
    res$target_id = unlist(lapply(str_split(res$target_id, "\\."), "[[", 1))
    out_name = paste0("./Data/tables/DTE","_",i, ".tsv")
    write.table(res, out_name, sep = "\t", quote = FALSE, row.names = FALSE)
    res$cell = i
    
    master = rbind(master,res)
  
    
  } else {
    
     Expr = so$obs_norm %>%  dplyr::select(target_id, sample, est_counts)
    Emat = tidyr::spread(Expr, key  = sample, est_counts)
    rownames(Emat) = unlist(lapply(str_split(Emat[,1],"\\|"), "[[",1))
    Emat = as.matrix(Emat[,-1])
    #dim(Emat)
    ## need to round est_counts to integer for RUVseq
    Emat = round(Emat)
    
    # Filter transcripts 
    filter <- apply(Emat, 1, function(x) length(x[x > 5]) >= 2) ##remove non-expressed transcripts (5 counts     in 2 samples)
    filtered <- Emat[filter,]   
    EDASeq::plotPCA(filtered, col=as.numeric(as.factor(s2c_tmp$condition))+2, cex=1.2, k=3, pch = as.numeric(as.factor(s2c_tmp$Lib)), main = paste("Sleuth",i) )
    
    so <- sleuth_fit(so, ~  condition, 'full')
    so <- sleuth_fit(so, ~ 1, 'reduced')
    so <- sleuth_lrt(so, 'reduced', 'full')
    so = sleuth_wt(so, "conditionnucleus")
    wt_results = sleuth_results(so, 'conditionnucleus')
    res =wt_results[!is.na(wt_results$pval), ]
    res$target_id = unlist(lapply(str_split(res$target_id, "\\."), "[[", 1))
    out_name = paste0("./Data/tables/DTE","_",i, ".tsv")
    write.table(res, out_name, sep = "\t", quote = FALSE, row.names = FALSE)
    res$cell = i

    master = rbind(master,res)
  }

}


write.csv(master, "./Data/tables/Master.csv", quote = FALSE, row.names = FALSE)
rm(Emat,Expr,filtered,Pair,pairmap, res, samples, wt_results, alignments, filter, set,set1,so,spikes, output, s2c_tmp, filespath, i, out_name, wts,x)
```


```{r, lncRNA_preprocess}

master = read.csv("./Data/tables/Master.csv", header = TRUE, stringsAsFactors = FALSE)

annots = rtracklayer::readGFF("./Data/Annotation/gencodev27lncRNAs.gtf", version = 2L)
annots = dplyr::filter(annots, type == "transcript")
# remove trailing decimal
annots$transcript_id = lapply(strsplit(annots$transcript_id, "\\."), "[[", 1)

lnc_match = match(master$target_id, annots$transcript_id)

lncRNAs = master[!is.na(lnc_match), ]

## set up Expression matrix lncRNAs x cell_type
mat = matrix(nrow = length(unique(lncRNAs$target_id)), ncol = length(unique(lncRNAs$cell)), data = NA)
colnames(mat) = unique(lncRNAs$cell)
rownames(mat) = unique(lncRNAs$target_id)

## Loop through and add fold-changes, leave NA if not detected
for (i in 1:nrow(lncRNAs)){
  l2fc = lncRNAs$b[i]
  target = lncRNAs$target_id[i]
  celltype = lncRNAs$cell[i]
  
  mat[rownames(mat) == target, colnames(mat) == celltype] = l2fc
}


div_cols = unlist(list(color = brewer.pal(11, "RdYlBu")))[11:1]

mat2 = mat
mat2[mat2 >= 8] = 8
mat2[mat2 <= -5] = -5
mat_breaks = c(min(mat2, na.rm = TRUE), -3, -1,  0,  1, 3, 6 ,max(mat2, na.rm = TRUE))
div_cols = div_cols[c(1,2,3,7,9,10,11)]




#pdf("./Figures/lncRNA_heatmap.pdf", onefile = TRUE)
pheatmap(mat2, cluster_rows = FALSE, cluster_cols = TRUE, labels_row = "", breaks = mat_breaks, color = div_cols, legend_breaks = c(-3, -1,0, 1, 3,6, max(mat2, na.rm = TRUE)), legend_labels = c(-3, -1, 0, 1, 3,6, "L2FC\n"), cex = 1.2 ) 

#dev.off()


#table(rowMeans(mat, na.rm = TRUE) < 0)

wts = table(s2c$cell)/nrow(s2c)
wts = wts[order(names(wts)) ]

mat = mat[ , order(colnames(mat))]


df = data.frame(target_id = rownames(mat))
df$l2fc = NA

for (i in 1:nrow(mat)){
  
  df$l2fc[i] = weighted.mean(mat[i,], wts, na.rm = TRUE)
}

cyfracs = c()
for ( i in which(df$l2fc < -1)){
  if (sum(!is.na(mat[i, ])) > 1){
  cyfracs = c(cyfracs, sum(mat[i, ] <= -1, na.rm = TRUE)/sum(!is.na(mat[i, ] )) *100)
  }
}


nucfracs = c()
for ( i in which(df$l2fc >  3)){
  if (sum(!is.na(mat[i, ])) > 1){
  nucfracs = c(nucfracs, sum(mat[i, ] > 3, na.rm = TRUE)/sum(!is.na(mat[i, ] )) *100)
  }
}

boxplot(nucfracs, cyfracs, col = c("#A50026", "#313695"), outline = FALSE, ylab = "Percent  Conserved", xlab = "LncRNAs", names = c("Nuclear","Cytosol"))

## get lncRNA cDNA sequences
library(biomaRt)
mart = biomaRt::useMart("ensembl", dataset = "hsapiens_gene_ensembl")

seq = biomaRt::getSequence(id = df$target_id, type="ensembl_transcript_id", seqType = "cdna", mart = mart)
df$cdna = seq$cdna[match(df$target_id, seq$ensembl_transcript_id)]

seq$transcript_length = as.numeric(lapply(seq$cdna, nchar))

for (i in 1:nrow(df)){
df$GC_content[i] =  sum(oligonucleotideFrequency(DNAString(df$cdna[i]), 1)[c(2,3)])/ sum(oligonucleotideFrequency(DNAString(df$cdna[i]), 1))
}


saveRDS(df, "./Data/DE_lncRNAs.rds")
```


```{r, feature_extraction}
Kmer_add = function(df, k){
  library(Biostrings)
  #df must contain "cdna" column
  #k is largest int of 
  kmer_mat = matrix( ncol = sum(4^seq(2, k)) , nrow = nrow(df), data =0)
  
  for (i in 1:nrow(df)){
    seq =DNAString(df$cdna[i])
   # len = df$transcript_length[i]
    index = 0
    for (j in 2:k) {
    kmers = oligonucleotideFrequency(seq, j)
    ind2 = index
    kmer_mat[i, (index + 1): (ind2 + (4^j) ) ] = as.vector(kmers)
    index = index + (4^j)
    }
  }
  
  nams =c()
  for (i in 2:k){
    nams =c(nams, names(oligonucleotideFrequency(seq, i)) )
  
  }
  colnames(kmer_mat) = nams
  df = cbind(df, kmer_mat)
  return(df)
}


df = Kmer_add(df, k = 5)


RNABP_Motif_add = function(df){
  library(Biostrings)
  
motifs_dir = file.path("./Data/motifs/Homo_sapiens_2017_09_07_CISBP/pwms_all_motifs")
mot_num = length(list.files(motifs_dir))

mat_mot = matrix(nrow = nrow(df), ncol = mot_num , data = 0)

for (i in 1:mot_num){
    fils = list.files(motifs_dir)[i]
    #some motif files from CISBP are completely empty and will throw an error so i added a try-catch here
    mot = try(read.table(paste0(motifs_dir, "/", fils), sep = "\t", row.names = 1, header = TRUE ), silent = FALSE)
    if (class(mot) != "try-error"){
        mot = t(mot)
# rownames(mot)
# [1] "A" "C" "G" "U"
## Motifs are in units of RNA so to get cDNA must reverse complement
# complement to DNA (A -> T, C -> G, G -> C, U -> A) then reverse column order
        #rownames(mot) = c("T","G","C", "A")
        #mot = mot[order(rownames(mot)), ncol(mot):1 ]
        rownames(mot)[4] = "T"
        #print(ncol(mot))
        
        for (j in 1:nrow(df)){
        #len = df$transcript_length[j]
        seq = df$cdna[j]
        counts = countPWM(mot, seq, min.score = "80%") 
        mat_mot[j,i] = counts
        }
    }    
}

df = cbind(df, mat_mot)
return(df)
}
df = RNABP_Motif_add(df)
saveRDS(df, "./Data/cdna_lncRNAs.rds")
```


```{r partition_frames}
rownames(df) = df$target_id
df = df %>% dplyr::select( -c(cdna, target_id))

drop_vars = colnames(df[ ,4:ncol(df)])[colSums(df[ ,4:ncol(df)])==0]
df = df %>% dplyr::select( -one_of(drop_vars))

mart = biomaRt::useMart(biomart="ensembl", dataset="hsapiens_gene_ensembl")
map = biomaRt::getBM(mart = mart, attributes = c("ensembl_transcript_id","transcript_biotype", "chromosome_name"), filters = "ensembl_transcript_id", values = rownames(df))
mapmatch = match(rownames(df), map$ensembl_transcript_id)
df = cbind(df, map[mapmatch, -1 ])

df$lincRNA = 0
df$lincRNA[df$transcript_biotype == "lincRNA"] = 1

df$antisense = 0
df$antisense[df$transcript_biotype == "antisense_RNA"] = 1

df$sense = 0
df$sense[grepl("^sense_", df$transcript_biotype)] = 1

df = df %>% dplyr::select(-transcript_biotype)

chroms =  as.data.frame(model.matrix(~df$chromosome_name))
chroms$`(Intercept)` = 0
chroms$`(Intercept)`[df$chromosome_name == 1] = 1
colnames(chroms)[1] = "df$chromosome_name1"
colnames(chroms) = unlist(lapply(strsplit(colnames(chroms), "\\$"), "[[", 2))

df = cbind(df, chroms)
df = df %>% dplyr::select( - chromosome_name)
saveRDS(df, "./Data/df_features.rds")

set.seed(54321)

spec = c(train = .7, test = .15, validate = .15)

g = sample(cut(
  seq(nrow(df)), 
  nrow(df)*cumsum(c(0,spec)),
  labels = names(spec)
))

res = split(df, g)


#verify splits equal whole == TRUE
sum(sapply(res, nrow)) == nrow(df)
#Check splits dont contain duplicates == FALSE
table(duplicated(c(rownames(res$train), rownames(res$test), rownames(res$validate))))

# Save final dataframes
saveRDS(res, "./Data/Training_frames.rds")

```

